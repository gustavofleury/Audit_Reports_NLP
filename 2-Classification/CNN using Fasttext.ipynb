{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn using Fasttext(final).ipynb","provenance":[{"file_id":"1sU0ePrM52Tem5lAPtze55ihzzuBFEy_M","timestamp":1587364916634}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"XYO2M1EuMFUK","colab_type":"code","outputId":"b6fed664-fec1-4c65-dc45-e05fcd189294","executionInfo":{"status":"ok","timestamp":1586702459534,"user_tz":-120,"elapsed":111234,"user":{"displayName":"Induraj PR","photoUrl":"","userId":"11528069712067702706"}},"colab":{"base_uri":"https://localhost:8080/","height":816}},"source":["!pip install tensorflow==1.15"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.15\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n","\u001b[K     |████████████████████████████████| 412.3MB 35kB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 35.2MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.28.1)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.2)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 41.2MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (46.1.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=a90247d8b0bdca2a9c5adf4a2523994cb3e4923d57dcabe9e5ffe2fd4a262c0e\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","Installing collected packages: tensorflow-estimator, gast, tensorboard, tensorflow\n","  Found existing installation: tensorflow-estimator 2.2.0rc0\n","    Uninstalling tensorflow-estimator-2.2.0rc0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorboard 2.2.0\n","    Uninstalling tensorboard-2.2.0:\n","      Successfully uninstalled tensorboard-2.2.0\n","  Found existing installation: tensorflow 2.2.0rc2\n","    Uninstalling tensorflow-2.2.0rc2:\n","      Successfully uninstalled tensorflow-2.2.0rc2\n","Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i7GozyeUx-6d","colab_type":"code","outputId":"def9123f-5fea-474e-bb60-99e2f4f14309","executionInfo":{"status":"ok","timestamp":1586702491435,"user_tz":-120,"elapsed":139227,"user":{"displayName":"Induraj PR","photoUrl":"","userId":"11528069712067702706"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#Libraries\n","import pandas as pd\n","import re\n","import nltk\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from string import punctuation\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","import spacy\n","from spacy.lang.pt.examples import sentences\n","import matplotlib.pyplot as plt\n","import scipy.sparse\n","from sklearn.decomposition import PCA\n","import pickle\n","#nlp = spacy.load('pt')\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE \n","import matplotlib.pyplot as plt\n","#pip install scipy==0.10.1\n","import gensim\n","from gensim.models import KeyedVectors\n","\n","!pip install https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.0/pt_core_news_sm-2.2.0.tar.gz\n","!python -m spacy download pt_core_news_sm\n","!python -m spacy link pt_core_news_sm pt --force\n","\n","nlp = spacy.load('pt')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","Collecting https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.0/pt_core_news_sm-2.2.0.tar.gz\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.0/pt_core_news_sm-2.2.0.tar.gz (21.2MB)\n","\u001b[K     |████████████████████████████████| 21.2MB 80kB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pt-core-news-sm==2.2.0) (2.2.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->pt-core-news-sm==2.2.0) (1.0.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->pt-core-news-sm==2.2.0) (3.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->pt-core-news-sm==2.2.0) (2.21.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->pt-core-news-sm==2.2.0) (0.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->pt-core-news-sm==2.2.0) (46.1.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->pt-core-news-sm==2.2.0) (1.0.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->pt-core-news-sm==2.2.0) (1.18.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->pt-core-news-sm==2.2.0) (0.6.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->pt-core-news-sm==2.2.0) (4.38.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->pt-core-news-sm==2.2.0) (7.4.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->pt-core-news-sm==2.2.0) (1.1.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->pt-core-news-sm==2.2.0) (2.0.3)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->pt-core-news-sm==2.2.0) (1.0.2)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->pt-core-news-sm==2.2.0) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->pt-core-news-sm==2.2.0) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->pt-core-news-sm==2.2.0) (2020.4.5.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->pt-core-news-sm==2.2.0) (1.24.3)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->pt-core-news-sm==2.2.0) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->pt-core-news-sm==2.2.0) (3.1.0)\n","Building wheels for collected packages: pt-core-news-sm\n","  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.0-cp36-none-any.whl size=21190448 sha256=e6a507d3308e3e8b3cb4b084d1f75ca97274ef83a0cf9c9cdb4205bca2486904\n","  Stored in directory: /root/.cache/pip/wheels/ed/71/eb/c36fcb1cb972e7cf25c322cf882aa35418703493c7dab84d90\n","Successfully built pt-core-news-sm\n","Installing collected packages: pt-core-news-sm\n","Successfully installed pt-core-news-sm-2.2.0\n","Collecting pt_core_news_sm==2.2.5\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2MB)\n","\u001b[K     |████████████████████████████████| 21.2MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.18.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.38.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (46.1.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.21.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.6.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.6.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.4.5.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.1.0)\n","Building wheels for collected packages: pt-core-news-sm\n","  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.5-cp36-none-any.whl size=21186282 sha256=7a16e2554548e3091367e0f2c804d4dbd3bd565ccbb3a7625607634ec9474447\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-6o3dh3ii/wheels/ea/94/74/ec9be8418e9231b471be5dc7e1b45dd670019a376a6b5bc1c0\n","Successfully built pt-core-news-sm\n","Installing collected packages: pt-core-news-sm\n","  Found existing installation: pt-core-news-sm 2.2.0\n","    Uninstalling pt-core-news-sm-2.2.0:\n","      Successfully uninstalled pt-core-news-sm-2.2.0\n","Successfully installed pt-core-news-sm-2.2.5\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('pt_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/pt\n","You can now load the model via spacy.load('pt')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r0ZCj7Gj99P-","colab_type":"code","outputId":"0398c29d-5d5f-4ab4-aa9f-56e5d3932dfa","executionInfo":{"status":"ok","timestamp":1586702494011,"user_tz":-120,"elapsed":2566,"user":{"displayName":"Induraj PR","photoUrl":"","userId":"11528069712067702706"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["from __future__ import division, print_function\n","from keras.callbacks import ModelCheckpoint\n","from keras.layers import Dense, Dropout, Reshape, Flatten, concatenate, Input, Conv1D, GlobalMaxPooling1D, Embedding\n","from keras.layers.recurrent import LSTM\n","from keras.models import Sequential\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Model\n","from keras.preprocessing import text"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"AxDw2blf-aKv","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7NYhJL6-yXBo","colab_type":"code","outputId":"e8b8d1e8-f328-481a-dd5f-a7ac4c6e81a6","executionInfo":{"status":"ok","timestamp":1586702532548,"user_tz":-120,"elapsed":40982,"user":{"displayName":"Induraj PR","photoUrl":"","userId":"11528069712067702706"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3B6xCz26HCFG","colab":{}},"source":["#Paths  #Import FILES\n","DATASETS_FOLDER = '/content/drive/My Drive/Research/DataSets/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IiUrsXZmf7LL","colab_type":"code","outputId":"cbed80e1-7eba-4263-a25e-cc13121b8bd0","executionInfo":{"status":"ok","timestamp":1586702534654,"user_tz":-120,"elapsed":2088,"user":{"displayName":"Induraj PR","photoUrl":"","userId":"11528069712067702706"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%run '/content/drive/My Drive/Fraud detection in internal auditing/Colab Notebooks/NLP functions_Gus.ipynb'\n","#%run '/content/drive/My Drive/Colab Notebooks/NLP-4-Classification-FUNCTIONS.ipynb'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qh8nBf9W-L-r","colab_type":"code","colab":{}},"source":["MAX_SEQUENCE_LENGTH = 5000\n","EMBEDDING_DIM = 300"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ms9bpVfwZ4ij","colab_type":"code","colab":{}},"source":["def overSamplingRISKs(df,rate):\n","  X = df \n","  not_HIGH = df[df.RISK!=\"HIGH\"]\n","  HIGH = df[df.RISK==\"HIGH\"]\n","  oversample_by= int((rate*((len(df[df.RISK!=\"HIGH\"])+len(df[df.RISK==\"HIGH\"]))-(len(df[df.RISK==\"HIGH\"]))))/(1-rate))\n","  # OVERsample minority\n","  high_upsampled = resample(HIGH,\n","                            replace=True, # sample with replacement\n","                            n_samples=oversample_by, # match number in majority class\n","                            random_state=27) # reproducible results\n","\n","  upsampled = pd.concat([not_HIGH, high_upsampled])\n","  print( upsampled.RISK.value_counts() )\n","\n","  return upsampled"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uE1-ROoV3zsj","colab_type":"code","outputId":"3100b147-6b91-47a4-f391-4d27d6a2ddc5","executionInfo":{"status":"ok","timestamp":1586702613708,"user_tz":-120,"elapsed":52883,"user":{"displayName":"Induraj PR","photoUrl":"","userId":"11528069712067702706"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["!git clone https://github.com/facebookresearch/fastText.git\n","%cd fastText\n","!pip install .\n","import fasttext\n","import fasttext.util"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'fastText'...\n","remote: Enumerating objects: 84, done.\u001b[K\n","remote: Counting objects:   1% (1/84)\u001b[K\rremote: Counting objects:   2% (2/84)\u001b[K\rremote: Counting objects:   3% (3/84)\u001b[K\rremote: Counting objects:   4% (4/84)\u001b[K\rremote: Counting objects:   5% (5/84)\u001b[K\rremote: Counting objects:   7% (6/84)\u001b[K\rremote: Counting objects:   8% (7/84)\u001b[K\rremote: Counting objects:   9% (8/84)\u001b[K\rremote: Counting objects:  10% (9/84)\u001b[K\rremote: Counting objects:  11% (10/84)\u001b[K\rremote: Counting objects:  13% (11/84)\u001b[K\rremote: Counting objects:  14% (12/84)\u001b[K\rremote: Counting objects:  15% (13/84)\u001b[K\rremote: Counting objects:  16% (14/84)\u001b[K\rremote: Counting objects:  17% (15/84)\u001b[K\rremote: Counting objects:  19% (16/84)\u001b[K\rremote: Counting objects:  20% (17/84)\u001b[K\rremote: Counting objects:  21% (18/84)\u001b[K\rremote: Counting objects:  22% (19/84)\u001b[K\rremote: Counting objects:  23% (20/84)\u001b[K\rremote: Counting objects:  25% (21/84)\u001b[K\rremote: Counting objects:  26% (22/84)\u001b[K\rremote: Counting objects:  27% (23/84)\u001b[K\rremote: Counting objects:  28% (24/84)\u001b[K\rremote: Counting objects:  29% (25/84)\u001b[K\rremote: Counting objects:  30% (26/84)\u001b[K\rremote: Counting objects:  32% (27/84)\u001b[K\rremote: Counting objects:  33% (28/84)\u001b[K\rremote: Counting objects:  34% (29/84)\u001b[K\rremote: Counting objects:  35% (30/84)\u001b[K\rremote: Counting objects:  36% (31/84)\u001b[K\rremote: Counting objects:  38% (32/84)\u001b[K\rremote: Counting objects:  39% (33/84)\u001b[K\rremote: Counting objects:  40% (34/84)\u001b[K\rremote: Counting objects:  41% (35/84)\u001b[K\rremote: Counting objects:  42% (36/84)\u001b[K\rremote: Counting objects:  44% (37/84)\u001b[K\rremote: Counting objects:  45% (38/84)\u001b[K\rremote: Counting objects:  46% (39/84)\u001b[K\rremote: Counting objects:  47% (40/84)\u001b[K\rremote: Counting objects:  48% (41/84)\u001b[K\rremote: Counting objects:  50% (42/84)\u001b[K\rremote: Counting objects:  51% (43/84)\u001b[K\rremote: Counting objects:  52% (44/84)\u001b[K\rremote: Counting objects:  53% (45/84)\u001b[K\rremote: Counting objects:  54% (46/84)\u001b[K\rremote: Counting objects:  55% (47/84)\u001b[K\rremote: Counting objects:  57% (48/84)\u001b[K\rremote: Counting objects:  58% (49/84)\u001b[K\rremote: Counting objects:  59% (50/84)\u001b[K\rremote: Counting objects:  60% (51/84)\u001b[K\rremote: Counting objects:  61% (52/84)\u001b[K\rremote: Counting objects:  63% (53/84)\u001b[K\rremote: Counting objects:  64% (54/84)\u001b[K\rremote: Counting objects:  65% (55/84)\u001b[K\rremote: Counting objects:  66% (56/84)\u001b[K\rremote: Counting objects:  67% (57/84)\u001b[K\rremote: Counting objects:  69% (58/84)\u001b[K\rremote: Counting objects:  70% (59/84)\u001b[K\rremote: Counting objects:  71% (60/84)\u001b[K\rremote: Counting objects:  72% (61/84)\u001b[K\rremote: Counting objects:  73% (62/84)\u001b[K\rremote: Counting objects:  75% (63/84)\u001b[K\rremote: Counting objects:  76% (64/84)\u001b[K\rremote: Counting objects:  77% (65/84)\u001b[K\rremote: Counting objects:  78% (66/84)\u001b[K\rremote: Counting objects:  79% (67/84)\u001b[K\rremote: Counting objects:  80% (68/84)\u001b[K\rremote: Counting objects:  82% (69/84)\u001b[K\rremote: Counting objects:  83% (70/84)\u001b[K\rremote: Counting objects:  84% (71/84)\u001b[K\rremote: Counting objects:  85% (72/84)\u001b[K\rremote: Counting objects:  86% (73/84)\u001b[K\rremote: Counting objects:  88% (74/84)\u001b[K\rremote: Counting objects:  89% (75/84)\u001b[K\rremote: Counting objects:  90% (76/84)\u001b[K\rremote: Counting objects:  91% (77/84)\u001b[K\rremote: Counting objects:  92% (78/84)\u001b[K\rremote: Counting objects:  94% (79/84)\u001b[K\rremote: Counting objects:  95% (80/84)\u001b[K\rremote: Counting objects:  96% (81/84)\u001b[K\rremote: Counting objects:  97% (82/84)\u001b[K\rremote: Counting objects:  98% (83/84)\u001b[K\rremote: Counting objects: 100% (84/84)\u001b[K\rremote: Counting objects: 100% (84/84), done.\u001b[K\n","remote: Compressing objects: 100% (61/61), done.\u001b[K\n","remote: Total 3768 (delta 35), reused 46 (delta 15), pack-reused 3684\u001b[K\n","Receiving objects: 100% (3768/3768), 8.20 MiB | 9.54 MiB/s, done.\n","Resolving deltas: 100% (2354/2354), done.\n","/content/fastText\n","Processing /content/fastText\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (2.5.0)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (46.1.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (1.18.2)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2875545 sha256=6555b7cd38b074ba61d489bb34488f0e943fb33603b3c5a084101f19043418a3\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-bejxm3p3/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n","Successfully built fasttext\n","Installing collected packages: fasttext\n","Successfully installed fasttext-0.9.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-20kCbVP2Xm9","colab_type":"code","colab":{}},"source":["#fasttext.load_model('/content/drive/My Drive/Fraud detection in internal auditing/wiki.pt.bin')\n","# fasttext.util.download_model('pt', if_exists='ignore') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJPASlc72XQH","colab_type":"code","outputId":"f4be5c9c-dcb6-437e-84fa-d9d82b68bf58","executionInfo":{"status":"ok","timestamp":1586704234455,"user_tz":-120,"elapsed":1590414,"user":{"displayName":"Induraj PR","photoUrl":"","userId":"11528069712067702706"}},"colab":{"base_uri":"https://localhost:8080/","height":683}},"source":["from keras.layers import MaxPooling1D\n","# list_of_years=['2016_DF_with_cleaned_stemmed_nonstemmed_v01.02.20.pkl','2017_DF_with_cleaned_stemmed_nonstemmed_v01.02.20.pkl','2018_DF_with_cleaned_stemmed_nonstemmed_v01.02.20.pkl','2019_DF_with_cleaned_stemmed_nonstemmed_v01.02.20.pkl']\n","list_of_years=['2016_DF_cleaned_not_balanced.pkl']\n","label_names = ['Risk_HIGH', 'Risk_MEDIUM-LOW']\n","for ele in list_of_years:\n","  filename = DATASETS_FOLDER+ele\n","  df = pd.read_pickle(filename)\n","  datatrain,datatest= train_test_split(df, test_size=0.30, random_state=42)\n","  datatrain = overSamplingRISKs(datatrain,0.30)\n","  ft = fasttext.load_model('/content/drive/My Drive/Research/DataSets/wiki.pt.bin')\n","  datatrain,datatest= train_test_split(df, test_size=0.30, random_state=42)\n","  Training_vocabulary = sorted(list(set(word for tokens in datatrain.token_filtered for word in tokens)))\n","  tokenizer= text.Tokenizer(num_words=5000)\n","  tokenizer.fit_on_texts(datatrain.sent_token_final.tolist())\n","  training_sequences = tokenizer.texts_to_sequences(datatrain.sent_token_final.tolist())\n","  train_word_index = tokenizer.word_index\n","  train_cnn_data = pad_sequences(training_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","  train_embedding_weights = np.zeros((len(train_word_index)+1, EMBEDDING_DIM))\n","  print(\"3\")\n","  ele_to_pop=[]\n","  for word,index in train_word_index.items():\n","    if word in ft:\n","      train_embedding_weights[index,:]=ft[word]\n","    else:\n","      train_embedding_weights[index,:]= np.zeros(EMBEDDING_DIM)\n","      ele_to_pop.append(word)\n","  train_embedding_weights= train_embedding_weights[~np.all(train_embedding_weights==0.0,axis=1)]\n","  for name,key in list(train_word_index.items()):\n","    if name in ele_to_pop:\n","      del train_word_index[name]\n","\n","  test_sequences = tokenizer.texts_to_sequences(datatest.sent_token_final.tolist())\n","  test_cnn_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","  x_train = train_cnn_data\n","  y_train = datatrain[label_names].values\n","  y_tr = y_train\n","\n","  x_test= test_cnn_data\n","  y_test= datatest[label_names].values\n","  y_te = y_test\n","\n","  model = Sequential()\n","  model.add(Embedding(len(train_word_index), EMBEDDING_DIM, weights=[train_embedding_weights], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n","  model.add(Dropout(0.5))\n","  convs = []\n","  filter_sizes = [2,3,4,5,6]\n","  for filter_size in filter_sizes:\n","    model.add(Conv1D(filters=200, kernel_size=filter_size, activation='relu',padding='valid'))\n","    model.add(MaxPooling1D())\n","  model.add(Dropout(0.1))\n","  model.add(Dense(256,activation='relu'))\n","  model.add(Dropout(0.2))\n","  model.add(Flatten())\n","  model.add(Dense(len(list(label_names)),activation='sigmoid'))\n","  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","  # model.summary()\n","\n","  \n","  model.fit(x_train,y_tr, batch_size=32, epochs=10,validation_data=(x_test,y_te))\n","\n","\n","  predictions_TRAIN=model.predict(train_cnn_data, batch_size=32, verbose=1)\n","  predictions= model.predict(test_cnn_data, batch_size=32, verbose=1)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["MEDIUM-LOW    12467\n","HIGH           5343\n","Name: RISK, dtype: int64\n"],"name":"stdout"},{"output_type":"stream","text":["Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"],"name":"stderr"},{"output_type":"stream","text":["3\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 12904 samples, validate on 5531 samples\n","Epoch 1/10\n","12904/12904 [==============================] - 123s 10ms/step - loss: 0.1579 - accuracy: 0.9641 - val_loss: 0.1520 - val_accuracy: 0.9649\n","Epoch 2/10\n","12904/12904 [==============================] - 114s 9ms/step - loss: 0.1505 - accuracy: 0.9661 - val_loss: 0.1521 - val_accuracy: 0.9649\n","Epoch 3/10\n","12904/12904 [==============================] - 114s 9ms/step - loss: 0.1509 - accuracy: 0.9661 - val_loss: 0.1528 - val_accuracy: 0.9649\n","Epoch 4/10\n","12904/12904 [==============================] - 114s 9ms/step - loss: 0.1504 - accuracy: 0.9661 - val_loss: 0.1527 - val_accuracy: 0.9649\n","Epoch 5/10\n","12904/12904 [==============================] - 114s 9ms/step - loss: 0.1502 - accuracy: 0.9661 - val_loss: 0.1536 - val_accuracy: 0.9649\n","Epoch 6/10\n","12904/12904 [==============================] - 113s 9ms/step - loss: 0.1495 - accuracy: 0.9661 - val_loss: 0.1527 - val_accuracy: 0.9649\n","Epoch 7/10\n","12904/12904 [==============================] - 113s 9ms/step - loss: 0.1499 - accuracy: 0.9661 - val_loss: 0.1529 - val_accuracy: 0.9649\n","Epoch 8/10\n","12904/12904 [==============================] - 113s 9ms/step - loss: 0.1496 - accuracy: 0.9661 - val_loss: 0.1552 - val_accuracy: 0.9649\n","Epoch 9/10\n","12904/12904 [==============================] - 113s 9ms/step - loss: 0.1503 - accuracy: 0.9661 - val_loss: 0.1526 - val_accuracy: 0.9649\n","Epoch 10/10\n","12904/12904 [==============================] - 112s 9ms/step - loss: 0.1503 - accuracy: 0.9661 - val_loss: 0.1520 - val_accuracy: 0.9649\n","12904/12904 [==============================] - 37s 3ms/step\n","5531/5531 [==============================] - 16s 3ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qZdICCew0uJ-","colab_type":"code","colab":{}},"source":["  predictions_TRAIN1= np.asarray([np.argmax(x) for x in predictions_TRAIN])\n","  predictions_1= np.asarray([np.argmax(x) for x in predictions])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j9jt9_WB2YZm","colab_type":"code","outputId":"93f82e7e-bc94-497d-df8f-efd84ac9992a","executionInfo":{"status":"ok","timestamp":1586704270141,"user_tz":-120,"elapsed":980,"user":{"displayName":"Induraj PR","photoUrl":"","userId":"11528069712067702706"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["acc, pre, rec, f1s = get_metrics(datatrain.FinalLabel,predictions_TRAIN1)\n","acc, pre, rec, f1s = get_metrics(datatest.FinalLabel,predictions_1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy: 0.9661  Precision: 0.9661  Recall: 1.0  F1 Score: 0.9828\n","Accuracy: 0.9649  Precision: 0.9649  Recall: 1.0  F1 Score: 0.9821\n"],"name":"stdout"}]}]}